global:
  repository: registry.sports-cloud.com:5000

sc-monitoring:
  default-http-backend:
    image:
      repository: gcr.io/google_containers
      tag: defaultbackend:1.0
      pullPolicy: IfNotPresent   
    deployment:
      resources:
        minCpu: 10m
        maxCpu: 10m
        minMem: 20Mi
        maxMem: 20Mi
      containerPort: 8080
      replicas: 1
      terminationGracePeriodSeconds: 60
      livenessPath: "/healthz"
      livenessProbeInitDelay: 30
      livenessProbeTimeoutSeconds: 5
      livenessProbePort: 8080  
    service:
      name: default-http-backend
      type: NodePort
      externalPort: 8080
      internalPort: 80
  logrotate:
    image:
      tag: sc-monitoring:0.0.1-alpha.1
      pullPolicy: IfNotPresent   
    deployment:
      resources:
        minCpu: 10m
        maxCpu: 10m
        minMem: 20Mi
        maxMem: 20Mi
      command:
      - "/scripts/execute-logrotate.sh"
      - "1800"     
    service:
      name: default-http-backend
      type: NodePort
      externalPort: 8080
      internalPort: 80
sc-services:
  deployment:
    terminationGracePeriodSeconds: 30
  image:
    repository: quay.io/coreos
    tag: alb-ingress-controller:1.0-alpha.7
    pullPolicy: Always
    env:
      AWS_REGION: "us-east-2"
      CLUSTER_NAME: "sports-cloud.k8s.local"
      AWS_ACCESS_KEY_ID: "AKIAI2L3MWG32WAGY5HQ"
      AWS_SECRET_ACCESS_KEY: "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"
      AWS_DEBUG: "false"
  data:
    indexing:
      elasticsearch:
        image:
            repository: quay.io/pires
            tag: docker-elasticsearch-kubernetes:6.0.0
            pullPolicy: Always
        pdb:
          master:
            maxUnavailable: 1
          data:
            maxUnavailable: 1
        services:
          data:
            internalPort: 9300
            role: data
            portName: transport
            clusterIP: None
          client:
            internalPort: 9200
            role: client
            portName: http
          discovery:
            internalPort: 9300
            role: master
            portName: transport
        deployment:
          curator:
            image: 
              repository:  quay.io/pires
              tag: docker-elasticsearch-curator:5.4.1
          master:
            role: master
            replicas: 3
            livenessProbe:
              port: transport
            ports:
              transport: 9300
            env:
              NETWORK_HOST: "_eth0_"
              NUMBER_OF_MASTERS: "2"
              NODE_MASTER: "true"
              NODE_INGEST: "false"
              NODE_DATA: "false"
              HTTP_ENABLE: "false"
              ES_JAVA_OPTS: "-Xms512m -Xmx512m"
          client:
            role: client
            replicas: 2
            livenessProbe:
              port: transport
            readinessProbe:
              port: http
              initialDelaySeconds: 20
              timeoutSeconds: 5
            ports:
              transport: 9300
              http: 9200
            env:
              NETWORK_HOST: "_eth0_"
              NODE_MASTER: "false"
              NODE_DATA: "false"
              HTTP_ENABLE: "true"
              ES_JAVA_OPTS: "-Xms512m -Xmx512m"
          data:
            role: data
            replicas: 3
            livenessProbe: 
              initialDelaySeconds: 20
              periodSeconds: 10
              port: transport
            storage: 60G
            ports:
              transport: 9300
            env:
              NETWORK_HOST: "_eth0_" 
              NODE_MASTER: "false"
              NODE_INGEST: "false"
              HTTP_ENABLE: "true"
              ES_JAVA_OPTS: "-Xms512m -Xmx512m"
  offline:
    zookeeper:
      image:
        repository: gcr.io/google_containers
        tag: kubernetes-zookeeper:1.0-3.4.10
        pullPolicy: Always
      pdb:
        maxUnavailable: 1
      deployment:
        replicas: 3
        resources:
          minCpu: "0.5"
          minMem: "1Gi"
        ports:
          client: 2181
          server: 2888
          leader-election: 3888   
        volumes:
          storage: 10Gi
        readinessProbe:
          initialDelaySeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          initialDelaySeconds: 10
          timeoutSeconds: 5
      serviceCs:
        ports: 
          client: 2181
      serviceHs:
        clusterIP: None
        ports:
          server: 2888
          leader-election: 3888
      ## End of zookeeper config. All other dependencies will follow after this . 
      ## This is done intentionally as zookeepr is the parent of all  other components in offline 
      batch-processing:
        spark-master:
          image:
            tag: spark-master:0.0.1-alpha.3
            pullPolicy: IfNotPresent  
          deployment:
            replicas: 2
            terminationGracePeriodSeconds: 10
            command:
            - "/scripts/start-master"
            ports: ["7077","8080"]
            resources:
                minCpu: "100m"
            livenessProbe:
              port: 8080
              initialDelaySeconds: 120
              periodSeconds: 20
              timeoutSeconds: 10
          service:
              name: spark-master
              clusterIP: None
              externalPort: 7077
              internalPort: 7077
        spark-worker:
          image:
            tag: spark-worker:0.0.1-alpha.13
            pullPolicy: IfNotPresent 
            env:
              SPARK_WORKER_OPTS: "-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.appDataTtl=259200" 
          deployment:
            livenessProbe:
              initialDelaySeconds: 120
              periodSeconds: 20
              timeoutSeconds: 20
            resources:
              cpu: 100m
            containerPort: 8081
            replicas: 3
            command: 
            - "/scripts/start-worker"
      streaming-platform:
        ## Represents all streaming data related paltform. The one platform we chose is confluent
        confluent:
          ## Kafka deployment 
          kafka:
            image:
              repository: gcr.io/google_containers
              tag: kubernetes-kafka:1.0-10.2.1
              pullPolicy: IfNotPresent 
            pdb:
              maxUnavailable: 1
            service:
              name: kafka
              type: NodePort
              clusterIP: None
              externalPort: 9092
              internalPort: 9092
            deployment:
              containerPort: 9092
              env:
                KAFKA_HEAP_OPTS:  "-Xmx2g -Xms1g"
                KAFKA_OPTS: "-Dlogging.level=INFO"
              terminationGracePeriodSeconds: 300
              replicas: 3
              resources:
                minCpu: "0.5"
                minMem: "1G"
                maxCpu: "0.5"
                maxMem: "3G"
              volumes:
                hostPath: /data/apps/sports-cloud/kafka/data
          ## The kafka connect deployment and service
          connect:
            image:
              tag: sc-cp-connect:0.0.1-alpha.13
              env:
                CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
                CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
                CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
                CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
                CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry.marathon.l4lb.thisdcos.directory:8081"
                CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
                CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry.marathon.l4lb.thisdcos.directory:8081"
                CONNECT_PLUGIN_PATH: "/data/kafka/connect/libs"
                CONNECT_REST_PORT: "8083"
                CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "3"
                CONNECT_GROUP_ID: "sc-connect-group"
                CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
                CONNECT_STATUS_STORAGE_TOPIC: "connect-sc-status"
                CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
                CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "3"
                CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "3"
                KAFKA_HEAP_OPTS: "-XX:+PrintGCDetails \
                -XX:+PrintGCTimeStamps \
                -XX:+PrintReferenceGC   \
                -XX:+ParallelRefProcEnabled \
                -XX:+PrintAdaptiveSizePolicy  \
                -XX:+UnlockExperimentalVMOptions \
                -XX:+UseG1GC  \
                -XX:G1MixedGCLiveThresholdPercent=25 \
                -XX:InitiatingHeapOccupancyPercent=10 \
                -Xmx3g"
                CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
                CONNECT_OFFSET_STORAGE_TOPIC: "connect-sc-offsets"
                CONNECT_CONFIG_STORAGE_TOPIC: "connect-sc-configs"
              pullPolicy: IfNotPresent 
            deployment:
              readinessProbe:
                initialDelaySeconds: 120
                periodSeconds: 20
                timeoutSeconds: 10
              containerPort: 8083
              replicas: 3   
              resources:
                maxMem: "4G"
                minMem: "1G"
                maxCpu: "2"
                minCpu: "0.5"
            service:
              name: kafka-connect
              type: NodePort
              externalPort: 8083
              internalPort: 8083
          rest-proxy:
            image: 
              repository: confluentinc
              tag: cp-kafka-rest:3.2.0
              env:
              pullPolicy: IfNotPresent 
            deployment:
              containerPort: 8082
              replicas: 1   
              resources:
                maxMem: "768M"
                minMem: "512M"
            service:
              name: kafka-rest-proxy
              type: NodePort
              externalPort: 8082
              internalPort: 8082
  online:
    sc-rest-layer:
      image:
        tag: sports-cloud-rest:0.0.1-alpha.23
        pullPolicy: IfNotPresent 
        env:
          JAVA_OPTS: "-Xmx1024M"
      deployment:
        containerPort: 9080
        replicas: 3 
        resources:
          maxMem: "1.5G"
          minMem: "1024M"
        livenessProbe:
          initialDelaySeconds: 120
          periodSeconds: 20
          timeoutSeconds: 10
        readinessProbe:
          initialDelaySeconds: 120
          periodSeconds: 20
          timeoutSeconds: 10
      service:
        name: sc-rest
        type: NodePort
        externalPort: 9080
        internalPort: 9080
    artifact-server:
      image:
        tag: artifact-server:0.0.1-alpha.1
        pullPolicy: IfNotPresent 
      deployment:
        containerPort: 9082
        replicas: 1 
        resources:
          maxMem: "256M"
          minMem: "100M"
        livenessProbe:
          initialDelaySeconds: 10
          timeoutSeconds: 5
      service:
        name: artifact-server
        type: NodePort
        clusterIP: 100.68.16.196
        externalPort: 9082
        internalPort: 9082
  tools:
    kubernetes-dashboard:
      # Default values for kubernetes-dashboard
      # This is a YAML-formatted file.
      # Declare name/value pairs to be passed into your templates.
      # name: value

      image: gcr.io/google_containers/kubernetes-dashboard-amd64
      imageTag: "v1.7.1"
      imagePullPolicy: "IfNotPresent"

      nodeSelector: {}

      httpPort: 80

      serviceType: NodePort

      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi

      ingress:
        ## If true, Kubernetes Dashboard Ingress will be created.
        ##
        enabled: true

        ## Kubernetes Dashboard Ingress annotations
        ##
        annotations:
          alb.ingress.kubernetes.io/scheme: internet-facing
          ingress.kubernetes.io/rewrite-target: /

        ## Kubernetes Dashboard Ingress hostnames
        ## Must be provided if Ingress is enabled
        ##
        hosts:
         - intsportscloud.slingbox.com

        ## Kubernetes Dashboard Ingress TLS configuration
        ## Secrets must be manually created in the namespace
        ##
        # tls:
        #   - secretName: kubernetes-dashboard-tls
        #     hosts:
        #       - kubernetes-dashboard.domain.com

      rbac:
        ## If true, create & use RBAC resources
        #
        create: false

        ## Ignored if rbac.create is true
        #
        serviceAccountName: default
    zeppelin:
      image:
        tag: zeppelin:0.0.1-alpha.6
        pullPolicy: IfNotPresent
        env:
          SPARK_HOME: /opt/spark
          ZEPPELIN_HOME: /opt/zeppelin
          ZEPPELIN_JAVA_OPTS: "-Dspark.jars: /opt/spark/jars/gcs-connector-latest-hadoop2.jar"
          CLASSPATH: "/opt/spark/lib/gcs-connector-latest-hadoop2.jar"
          ZEPPELIN_NOTEBOOK_DIR: "/opt/zeppelin/notebook"
          ZEPPELIN_MEM: -Xmx3g
          ZEPPELIN_PORT: 8080
          PYTHONPATH: "/opt/spark/python:/opt/spark/python/lib/py4j-0.8.2.1-src.zip"
          ZEPPELIN_CONF_DIR: "/opt/zeppelin/conf"
          APP_SPARK_MASTERS_EPS: "local[3]"
      deployment:
        command:
        - /opt/zeppelin/bin/docker-zeppelin.sh
        resources:
          minCpu: 2
          maxCpu: 3
          minMem: 2G
          maxMem: 3G
        containerPort: 8080
        replicas: 1   
      service:
        name: zeppelin
        type: NodePort
        externalPort: 8080
        internalPort: 80
      spark:
        driverMemory: 2g
        executorMemory: 2g
        numExecutors: 2
        coresMax: 3
    kibana:
      image:
        repository: "docker.elastic.co/kibana"
        tag: "kibana-oss:6.0.0"
        pullPolicy: IfNotPresent   
        env:
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 1000m
        containerPort: 5601
        replicas: 1   
      service:
        name: kibana
        type: NodePort
        externalPort: 5601
        internalPort: 80
      ingress:
        ## If true, Kubernetes Dashboard Ingress will be created.
        ##
        enabled: true

        ## Kubernetes Dashboard Ingress annotations
        ##
        annotations:
          alb.ingress.kubernetes.io/scheme: internet-facing
          ingress.kubernetes.io/rewrite-target: /

        ## Kubernetes Dashboard Ingress hostnames
        ## Must be provided if Ingress is enabled
        ##
        hosts:
         - intsc-kibana.slingbox.com
    spark-ui-proxy-1:
      image:
        repository: elsonrodriguez
        tag: spark-ui-proxy:1.0
        pullPolicy: IfNotPresent   
      deployment:
        resources:
          cpu: 100m
        containerPort: 80
        replicas: 1   
        args: 
        - "80"
        livenessProbeInitDelay: 120
        livenessProbeTimeoutSeconds: 5
        livenessProbePort: 80  
      service:
        name: spark-ui-proxy-1
        type: NodePort
        externalPort: 80
        internalPort: 80
    spark-ui-proxy-2:
      image:
        repository: elsonrodriguez
        tag: spark-ui-proxy:1.0
        pullPolicy: IfNotPresent   
      deployment:
        resources:
          cpu: 100m
        containerPort: 80
        replicas: 1   
        args: 
        - "80"
        livenessProbeInitDelay: 120
        livenessProbeTimeoutSeconds: 5
        livenessProbePort: 80  
      service:
        name: spark-ui-proxy-2
        type: NodePort
        externalPort: 80
        internalPort: 80
sc-jobs:
  thuuz-download-job:
    ingress: {}
    service: {}
    image:
      tag: sc-job-scheduler:0.0.1-alpha.13
      pullPolicy: IfNotPresent
      env:
        cmsHost: "cbd46b77"
        cmsSummaryUrl: "cms/publish3/domain/summary/1.json"
    cronJob:
      args: 
      - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
      - "download-thuuz"
      type: ClusterIP
      restartPolicy: Never
      schedule: "0 */5 * * *"
  summary-download-job:
    ingress: {}
    service: {}
    deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 256Mi
          maxMem: 512Mi
    image:
      tag: sc-job-scheduler:0.0.1-alpha.13
      pullPolicy: IfNotPresent
      env:
        cmsHost: "cbd46b77"
        cmsSummaryUrl: "cms/publish3/domain/summary/1.json"
        JAVA_OPTS: "-Xmx512M"
    cronJob:
      args: 
      - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
      - "download-summary"
      type: ClusterIP
      restartPolicy: Never
      schedule: "20 0/5 * * *"
  schedules-download-job:
    ingress: {}
    service: {}
    deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 256Mi
          maxMem: 512Mi
    image:
      tag: sc-job-scheduler:0.0.1-alpha.13
      pullPolicy: IfNotPresent
      env:
        cmsHost: "cbd46b77"
        cmsSummaryUrl: "cms/publish3/domain/summary/1.json"
        JAVA_OPTS: "-Xmx512M"
    cronJob:
      args: 
      - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
      - "download-schedules"
      type: ClusterIP
      restartPolicy: Never
      schedule: "40 0/5 * * *"
  nfl:    
    connect-meta-batch-nfl:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "nfl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-meta-batch-nfl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NflTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_nfl"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    connect-content-match-nfl:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "nfl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-content-match-nfl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: NflContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_nfl"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 7 * * *"
    connect-live-info-nfl:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "nfl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-live-info-nfl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.NflLiveDataMuncher
        jobName: NflLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_nfl"
        - "live_info"
      Job:
        command: 
        type: ClusterIP
        restartPolicy: OnFailure
    spark-batch-live-score-nfl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NflBoxScore
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "NFLLIVEINFO"
        - "live_info_nfl"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "0 8 * * *"
  mlb:    
    connect-meta-batch-mlb:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "mlb"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-meta-batch-ts-mlb:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: MlbTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_mlb"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    spark-meta-batch-ps-mlb:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: MlbPlayerStatsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "PLAYERSTATS"
        - "meta_batch_mlb"
        - "player_stats"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "15 * * * *"
    connect-content-match-mlb:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "mlb"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-content-match-mlb:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: MlbContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_mlb"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "5 8 * * *"
    connect-live-info-mlb:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "mlb"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-live-info-mlb:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.MlbLiveDataMuncher
        jobName: MlbLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_mlb"
        - "live_info"
      Job:
        command: 
        type: ClusterIP
        restartPolicy: OnFailure
    spark-batch-live-score-mlb:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: MlbBoxScore
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "LIVEINFO"
        - "live_info_mlb"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "5 8 * * *"
  ncaaf:    
    connect-meta-batch-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "ncaaf"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-meta-batch-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NcaafTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_ncaaf"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    connect-content-match-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "ncaaf"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    spark-content-match-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: NcaafContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_ncaaf"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "30 7 * * *"
    connect-live-info-ncaaf:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "ncaaf"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-live-info-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.NflLiveDataMuncher
        jobName: NcaafLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_ncaaf"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: OnFailure
        schedule: "30 7 * * *"
    spark-batch-live-score-ncaaf:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NcaafBoxScore
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "NCAAFLIVEINFO"
        - "live_info_ncaaf"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "3 8 * * *"
  nba:
    connect-content-match-nba:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "nba"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-meta-batch-nba:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "nba"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-live-info-nba:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "nba"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-meta-batch-ts-nba:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NbaTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_nba"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    spark-meta-batch-pstats-nba:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.nba.NbaMetaDataMuncher
        jobName: NbaPlayerStatsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "PLAYERSTATS"
        - "meta_batch_nba"
        - "player_stats"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 5 * * *"
    spark-content-match-nba:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: NbaContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_nba"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 7 * * *"
    spark-live-info-nba:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.NbaLiveDataMuncher
        jobName: NbaLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_nba"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: OnFailure
        schedule: "30 7 * * *"
    spark-batch-live-score-nba:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NbaBoxScore
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "NBALIVEINFO"
        - "live_info_nba"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "5 8 * * *"
  ncaab:
    connect-content-match-ncaab:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "ncaab"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-meta-batch-ncaab:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "ncaab"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-live-info-ncaab:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "ncaab"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-meta-batch-ts-ncaab:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NcaabTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_ncaab"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    spark-meta-batch-pstats-ncaab:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NcaabPlayerStatsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "PLAYERSTATS"
        - "meta_batch_ncaab"
        - "player_stats"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 5 * * *"
    spark-content-match-ncaab:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: NcaabContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_ncaab"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 7 * * *"
    spark-live-info-ncaab:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.NbaLiveDataMuncher
        jobName: NcaabLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_ncaab"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: OnFailure
        schedule: "30 7 * * *"
    spark-batch-live-score-ncaab:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NcaabBoxScore
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "NCAABLIVEINFO"
        - "live_info_ncaab"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "5 8 * * *"
  soccer:
    spark-content-match-soccer:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.20
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.leagues.SoccerContentMatcher
        jobName: SoccerContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_soccer"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 0/7 * * *"
    connect-live-info-soccer:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        args: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "rest-parser-jobs"
        - "com.slingmedia.sportscloud.rest.parsers.leagues.soccer.SoccerLiveParser"
        - "live_info_soccer"
        type: ClusterIP
        restartPolicy: OnFailure
        concurrencyPolicy: Replace
    spark-live-info-soccer:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.20
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.SoccerLiveDataMuncher
        jobName: SoccerLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_soccer"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "30 7 * * *"
  nhl:
    connect-content-match-nhl:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectContentMatchJob"
        - "nhl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-meta-batch-nhl:
      ingress: {}
      service: {}
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectMetaBatchJob"
        - "nhl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/15 * * * *"
    connect-live-info-nhl:
      ingress: {}
      service: {}
      deployment:
        resources:
          minCpu: 100m
          maxCpu: 100m
          minMem: 64Mi
          maxMem: 64Mi
      image:
        tag: sc-job-scheduler:0.0.1-alpha.13
        pullPolicy: IfNotPresent
        env:
      cronJob:
        command: 
        - "/deploy-scheduled-jobs/scheduled-job-driver.sh"
        - "connect-jobs"
        - "com.slingmedia.sportscloud.schedulers.KafkaConnectLiveInfoJob"
        - "nhl"
        type: ClusterIP
        restartPolicy: Never
        concurrencyPolicy: Replace
        schedule: "0/3 * * * *"
    spark-meta-batch-ts-nhl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NhlTeamStandingsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "TEAMSTANDINGS"
        - "meta_batch_nhl"
        - "team_standings"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "20 5 * * *"
    spark-meta-batch-pstats-nhl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.meta.impl.DefaultMetaDataMuncher
        jobName: NhlPlayerStatsMetaDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "PLAYERSTATS"
        - "meta_batch_nhl"
        - "player_stats"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 5 * * *"
    spark-content-match-nhl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.batch.impl.ContentMatcher
        jobName: NhlContentDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "content_match_nhl"
        - "game_schedule"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "40 7 * * *"
    spark-live-info-nhl:
      ingress: {}
      service: {}
      image:
        tag: spark-job:0.0.1-alpha.16
        pullPolicy: IfNotPresent
        env:
      sparkJobArgs:
        className: com.slingmedia.sportscloud.offline.streaming.live.impl.NbaLiveDataMuncher
        jobName: NhlLiveDataMuncher
        driverMem: 2G
        executorMem: 2G
        executorCores: 2
        parallelism: 4
        execArgs:
        - "live_info_nhl"
        - "live_info"
      cronJob:
        command: 
        type: ClusterIP
        restartPolicy: Never
        schedule: "30 7 * * *"

